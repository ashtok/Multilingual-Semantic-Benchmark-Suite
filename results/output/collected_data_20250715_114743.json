{
  "timestamp": "20250715_114743",
  "results": [
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\High\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.61,
      "acc_stderr,none": 0.009958228723006411,
      "acc_norm,none": 0.63375,
      "acc_norm_stderr,none": 0.009836320676970411,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\High\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.405,
      "acc_stderr,none": 0.01553113699045304,
      "acc_norm,none": 0.402,
      "acc_norm_stderr,none": 0.015512467135715066,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\High\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.5353333333333333,
      "acc_stderr,none": 0.012881964150338793,
      "acc_norm,none": 0.5706666666666667,
      "acc_norm_stderr,none": 0.012784617545263777,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\High\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.808,
      "acc_stderr,none": 0.024960691989171998,
      "acc_norm,none": 0.812,
      "acc_norm_stderr,none": 0.0247603777277505,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\High\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.5008333333333334,
      "acc_stderr,none": 0.010208320041221635,
      "acc_norm,none": 0.4870833333333333,
      "acc_norm_stderr,none": 0.01020492732833829,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\High\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.3800403225806452,
      "acc_stderr,none": 0.015419125156073339,
      "acc_norm,none": 0.3639112903225806,
      "acc_norm_stderr,none": 0.015283393013872468,
      "n_samples_original": 992,
      "n_samples_effective": 992,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\High\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.37133333333333335,
      "acc_stderr,none": 0.01247933285175456,
      "acc_norm,none": 0.4013333333333333,
      "acc_norm_stderr,none": 0.012660309957688232,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\High\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.756,
      "acc_stderr,none": 0.027217995464553175,
      "acc_norm,none": 0.704,
      "acc_norm_stderr,none": 0.02892893938837963,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\High\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.4166666666666667,
      "acc_stderr,none": 0.0100655532824917,
      "acc_norm,none": 0.3129166666666667,
      "acc_norm_stderr,none": 0.00946681588039243,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\High\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.333,
      "acc_stderr,none": 0.01491084616422986,
      "acc_norm,none": 0.237,
      "acc_norm_stderr,none": 0.013454070462577966,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\High\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.37733333333333335,
      "acc_stderr,none": 0.012519574770236533,
      "acc_norm,none": 0.31866666666666665,
      "acc_norm_stderr,none": 0.01203503397765781,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\High\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.48,
      "acc_stderr,none": 0.031660853408495185,
      "acc_norm,none": 0.396,
      "acc_norm_stderr,none": 0.030993197854577853,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\High\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.34375,
      "acc_stderr,none": 0.00969707797099156,
      "acc_norm,none": 0.22875,
      "acc_norm_stderr,none": 0.008575570386944793,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\High\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.3004032258064516,
      "acc_stderr,none": 0.01456261499632924,
      "acc_norm,none": 0.22782258064516128,
      "acc_norm_stderr,none": 0.013323554568901394,
      "n_samples_original": 992,
      "n_samples_effective": 992,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\High\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.30733333333333335,
      "acc_stderr,none": 0.011916978642131138,
      "acc_norm,none": 0.26,
      "acc_norm_stderr,none": 0.011329264531434308,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\High\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.424,
      "acc_stderr,none": 0.03131803437491615,
      "acc_norm,none": 0.176,
      "acc_norm_stderr,none": 0.02413349752545711,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\High\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.7879166666666667,
      "acc_stderr,none": 0.008345998261206244,
      "acc_norm,none": 0.78,
      "acc_norm_stderr,none": 0.008457529431520559,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\High\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.658,
      "acc_stderr,none": 0.015008706182121726,
      "acc_norm,none": 0.667,
      "acc_norm_stderr,none": 0.014910846164229876,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\High\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.732,
      "acc_stderr,none": 0.01143989718040901,
      "acc_norm,none": 0.7833333333333333,
      "acc_norm_stderr,none": 0.010640659310800672,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\High\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.884,
      "acc_stderr,none": 0.02029342980308387,
      "acc_norm,none": 0.868,
      "acc_norm_stderr,none": 0.02145098082403809,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\High\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.70125,
      "acc_stderr,none": 0.0093449131639903,
      "acc_norm,none": 0.6629166666666667,
      "acc_norm_stderr,none": 0.009651237099023628,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\High\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.5655241935483871,
      "acc_stderr,none": 0.01574604782985797,
      "acc_norm,none": 0.5514112903225806,
      "acc_norm_stderr,none": 0.01579883885000548,
      "n_samples_original": 992,
      "n_samples_effective": 992,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\High\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.47333333333333333,
      "acc_stderr,none": 0.012895869942232146,
      "acc_norm,none": 0.4693333333333333,
      "acc_norm_stderr,none": 0.012889936799075373,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\High\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.904,
      "acc_stderr,none": 0.018668961419477163,
      "acc_norm,none": 0.82,
      "acc_norm_stderr,none": 0.02434689065029353,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\High\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752431769.7658036,
      "evaluation_time": "829.3948865570128",
      "acc,none": 0.7383333333333333,
      "acc_stderr,none": 0.008973984497330143,
      "acc_norm,none": 0.7329166666666667,
      "acc_norm_stderr,none": 0.009033074015690427,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\High\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752431769.7658036,
      "evaluation_time": "829.3948865570128",
      "acc,none": 0.524,
      "acc_stderr,none": 0.015801065586651755,
      "acc_norm,none": 0.527,
      "acc_norm_stderr,none": 0.01579621855130262,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\High\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752431769.7658036,
      "evaluation_time": "829.3948865570128",
      "acc,none": 0.6146666666666667,
      "acc_stderr,none": 0.012570058656192325,
      "acc_norm,none": 0.6626666666666666,
      "acc_norm_stderr,none": 0.01221170698805369,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\High\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752431769.7658036,
      "evaluation_time": "829.3948865570128",
      "acc,none": 0.88,
      "acc_stderr,none": 0.020593600596839946,
      "acc_norm,none": 0.868,
      "acc_norm_stderr,none": 0.021450980824038103,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\High\\Qwen3-8B.json",
      "date": 1752419140.5423734,
      "evaluation_time": "912.9916552146897",
      "acc,none": 0.7483333333333333,
      "acc_stderr,none": 0.008860235590600556,
      "acc_norm,none": 0.7695833333333333,
      "acc_norm_stderr,none": 0.008597449780109416,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\High\\Qwen3-8B.json",
      "date": 1752419140.5423734,
      "evaluation_time": "912.9916552146897",
      "acc,none": 0.568,
      "acc_stderr,none": 0.015672320237336206,
      "acc_norm,none": 0.592,
      "acc_norm_stderr,none": 0.015549205052920673,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\High\\Qwen3-8B.json",
      "date": 1752419140.5423734,
      "evaluation_time": "912.9916552146897",
      "acc,none": 0.692,
      "acc_stderr,none": 0.011924154350364261,
      "acc_norm,none": 0.74,
      "acc_norm_stderr,none": 0.01132926453143431,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\High\\Qwen3-8B.json",
      "date": 1752419140.5423734,
      "evaluation_time": "912.9916552146897",
      "acc,none": 0.868,
      "acc_stderr,none": 0.0214509808240381,
      "acc_norm,none": 0.86,
      "acc_norm_stderr,none": 0.02198940964524027,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Low\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.61,
      "acc_stderr,none": 0.009958228723006411,
      "acc_norm,none": 0.63375,
      "acc_norm_stderr,none": 0.009836320676970411,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Low\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.405,
      "acc_stderr,none": 0.01553113699045304,
      "acc_norm,none": 0.402,
      "acc_norm_stderr,none": 0.015512467135715066,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Low\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.5353333333333333,
      "acc_stderr,none": 0.012881964150338793,
      "acc_norm,none": 0.5706666666666667,
      "acc_norm_stderr,none": 0.012784617545263777,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Low\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.808,
      "acc_stderr,none": 0.024960691989171998,
      "acc_norm,none": 0.812,
      "acc_norm_stderr,none": 0.0247603777277505,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\Low\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.5008333333333334,
      "acc_stderr,none": 0.010208320041221635,
      "acc_norm,none": 0.4870833333333333,
      "acc_norm_stderr,none": 0.01020492732833829,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\Low\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.3800403225806452,
      "acc_stderr,none": 0.015419125156073339,
      "acc_norm,none": 0.3639112903225806,
      "acc_norm_stderr,none": 0.015283393013872468,
      "n_samples_original": 992,
      "n_samples_effective": 992,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\Low\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.37133333333333335,
      "acc_stderr,none": 0.01247933285175456,
      "acc_norm,none": 0.4013333333333333,
      "acc_norm_stderr,none": 0.012660309957688232,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\Low\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.756,
      "acc_stderr,none": 0.027217995464553175,
      "acc_norm,none": 0.704,
      "acc_norm_stderr,none": 0.02892893938837963,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Low\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.4166666666666667,
      "acc_stderr,none": 0.0100655532824917,
      "acc_norm,none": 0.3129166666666667,
      "acc_norm_stderr,none": 0.00946681588039243,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Low\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.333,
      "acc_stderr,none": 0.01491084616422986,
      "acc_norm,none": 0.237,
      "acc_norm_stderr,none": 0.013454070462577966,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Low\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.37733333333333335,
      "acc_stderr,none": 0.012519574770236533,
      "acc_norm,none": 0.31866666666666665,
      "acc_norm_stderr,none": 0.01203503397765781,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Low\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.48,
      "acc_stderr,none": 0.031660853408495185,
      "acc_norm,none": 0.396,
      "acc_norm_stderr,none": 0.030993197854577853,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\Low\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.34375,
      "acc_stderr,none": 0.00969707797099156,
      "acc_norm,none": 0.22875,
      "acc_norm_stderr,none": 0.008575570386944793,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\Low\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.3004032258064516,
      "acc_stderr,none": 0.01456261499632924,
      "acc_norm,none": 0.22782258064516128,
      "acc_norm_stderr,none": 0.013323554568901394,
      "n_samples_original": 992,
      "n_samples_effective": 992,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\Low\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.30733333333333335,
      "acc_stderr,none": 0.011916978642131138,
      "acc_norm,none": 0.26,
      "acc_norm_stderr,none": 0.011329264531434308,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\Low\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.424,
      "acc_stderr,none": 0.03131803437491615,
      "acc_norm,none": 0.176,
      "acc_norm_stderr,none": 0.02413349752545711,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Low\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.7879166666666667,
      "acc_stderr,none": 0.008345998261206244,
      "acc_norm,none": 0.78,
      "acc_norm_stderr,none": 0.008457529431520559,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Low\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.658,
      "acc_stderr,none": 0.015008706182121726,
      "acc_norm,none": 0.667,
      "acc_norm_stderr,none": 0.014910846164229876,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Low\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.732,
      "acc_stderr,none": 0.01143989718040901,
      "acc_norm,none": 0.7833333333333333,
      "acc_norm_stderr,none": 0.010640659310800672,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Low\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.884,
      "acc_stderr,none": 0.02029342980308387,
      "acc_norm,none": 0.868,
      "acc_norm_stderr,none": 0.02145098082403809,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\Low\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.70125,
      "acc_stderr,none": 0.0093449131639903,
      "acc_norm,none": 0.6629166666666667,
      "acc_norm_stderr,none": 0.009651237099023628,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\Low\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.5655241935483871,
      "acc_stderr,none": 0.01574604782985797,
      "acc_norm,none": 0.5514112903225806,
      "acc_norm_stderr,none": 0.01579883885000548,
      "n_samples_original": 992,
      "n_samples_effective": 992,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\Low\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.47333333333333333,
      "acc_stderr,none": 0.012895869942232146,
      "acc_norm,none": 0.4693333333333333,
      "acc_norm_stderr,none": 0.012889936799075373,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\Low\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.904,
      "acc_stderr,none": 0.018668961419477163,
      "acc_norm,none": 0.82,
      "acc_norm_stderr,none": 0.02434689065029353,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Low\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752431769.7658036,
      "evaluation_time": "829.3948865570128",
      "acc,none": 0.7383333333333333,
      "acc_stderr,none": 0.008973984497330143,
      "acc_norm,none": 0.7329166666666667,
      "acc_norm_stderr,none": 0.009033074015690427,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Low\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752431769.7658036,
      "evaluation_time": "829.3948865570128",
      "acc,none": 0.524,
      "acc_stderr,none": 0.015801065586651755,
      "acc_norm,none": 0.527,
      "acc_norm_stderr,none": 0.01579621855130262,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Low\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752431769.7658036,
      "evaluation_time": "829.3948865570128",
      "acc,none": 0.6146666666666667,
      "acc_stderr,none": 0.012570058656192325,
      "acc_norm,none": 0.6626666666666666,
      "acc_norm_stderr,none": 0.01221170698805369,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Low\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752431769.7658036,
      "evaluation_time": "829.3948865570128",
      "acc,none": 0.88,
      "acc_stderr,none": 0.020593600596839946,
      "acc_norm,none": 0.868,
      "acc_norm_stderr,none": 0.021450980824038103,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Low\\Qwen3-8B.json",
      "date": 1752419140.5423734,
      "evaluation_time": "912.9916552146897",
      "acc,none": 0.7483333333333333,
      "acc_stderr,none": 0.008860235590600556,
      "acc_norm,none": 0.7695833333333333,
      "acc_norm_stderr,none": 0.008597449780109416,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Low\\Qwen3-8B.json",
      "date": 1752419140.5423734,
      "evaluation_time": "912.9916552146897",
      "acc,none": 0.568,
      "acc_stderr,none": 0.015672320237336206,
      "acc_norm,none": 0.592,
      "acc_norm_stderr,none": 0.015549205052920673,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Low\\Qwen3-8B.json",
      "date": 1752419140.5423734,
      "evaluation_time": "912.9916552146897",
      "acc,none": 0.692,
      "acc_stderr,none": 0.011924154350364261,
      "acc_norm,none": 0.74,
      "acc_norm_stderr,none": 0.01132926453143431,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Low\\Qwen3-8B.json",
      "date": 1752419140.5423734,
      "evaluation_time": "912.9916552146897",
      "acc,none": 0.868,
      "acc_stderr,none": 0.0214509808240381,
      "acc_norm,none": 0.86,
      "acc_norm_stderr,none": 0.02198940964524027,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Medium\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.61,
      "acc_stderr,none": 0.009958228723006411,
      "acc_norm,none": 0.63375,
      "acc_norm_stderr,none": 0.009836320676970411,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Medium\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.405,
      "acc_stderr,none": 0.01553113699045304,
      "acc_norm,none": 0.402,
      "acc_norm_stderr,none": 0.015512467135715066,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Medium\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.5353333333333333,
      "acc_stderr,none": 0.012881964150338793,
      "acc_norm,none": 0.5706666666666667,
      "acc_norm_stderr,none": 0.012784617545263777,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Medium\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.808,
      "acc_stderr,none": 0.024960691989171998,
      "acc_norm,none": 0.812,
      "acc_norm_stderr,none": 0.0247603777277505,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\Medium\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.5008333333333334,
      "acc_stderr,none": 0.010208320041221635,
      "acc_norm,none": 0.4870833333333333,
      "acc_norm_stderr,none": 0.01020492732833829,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\Medium\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.3800403225806452,
      "acc_stderr,none": 0.015419125156073339,
      "acc_norm,none": 0.3639112903225806,
      "acc_norm_stderr,none": 0.015283393013872468,
      "n_samples_original": 992,
      "n_samples_effective": 992,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\Medium\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.37133333333333335,
      "acc_stderr,none": 0.01247933285175456,
      "acc_norm,none": 0.4013333333333333,
      "acc_norm_stderr,none": 0.012660309957688232,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\Medium\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.756,
      "acc_stderr,none": 0.027217995464553175,
      "acc_norm,none": 0.704,
      "acc_norm_stderr,none": 0.02892893938837963,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Medium\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.4166666666666667,
      "acc_stderr,none": 0.0100655532824917,
      "acc_norm,none": 0.3129166666666667,
      "acc_norm_stderr,none": 0.00946681588039243,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Medium\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.333,
      "acc_stderr,none": 0.01491084616422986,
      "acc_norm,none": 0.237,
      "acc_norm_stderr,none": 0.013454070462577966,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Medium\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.37733333333333335,
      "acc_stderr,none": 0.012519574770236533,
      "acc_norm,none": 0.31866666666666665,
      "acc_norm_stderr,none": 0.01203503397765781,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Medium\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.48,
      "acc_stderr,none": 0.031660853408495185,
      "acc_norm,none": 0.396,
      "acc_norm_stderr,none": 0.030993197854577853,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\Medium\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.34375,
      "acc_stderr,none": 0.00969707797099156,
      "acc_norm,none": 0.22875,
      "acc_norm_stderr,none": 0.008575570386944793,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\Medium\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.3004032258064516,
      "acc_stderr,none": 0.01456261499632924,
      "acc_norm,none": 0.22782258064516128,
      "acc_norm_stderr,none": 0.013323554568901394,
      "n_samples_original": 992,
      "n_samples_effective": 992,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\Medium\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.30733333333333335,
      "acc_stderr,none": 0.011916978642131138,
      "acc_norm,none": 0.26,
      "acc_norm_stderr,none": 0.011329264531434308,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\Medium\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.424,
      "acc_stderr,none": 0.03131803437491615,
      "acc_norm,none": 0.176,
      "acc_norm_stderr,none": 0.02413349752545711,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Medium\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.7879166666666667,
      "acc_stderr,none": 0.008345998261206244,
      "acc_norm,none": 0.78,
      "acc_norm_stderr,none": 0.008457529431520559,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Medium\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.658,
      "acc_stderr,none": 0.015008706182121726,
      "acc_norm,none": 0.667,
      "acc_norm_stderr,none": 0.014910846164229876,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Medium\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.732,
      "acc_stderr,none": 0.01143989718040901,
      "acc_norm,none": 0.7833333333333333,
      "acc_norm_stderr,none": 0.010640659310800672,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Medium\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.884,
      "acc_stderr,none": 0.02029342980308387,
      "acc_norm,none": 0.868,
      "acc_norm_stderr,none": 0.02145098082403809,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\Medium\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.70125,
      "acc_stderr,none": 0.0093449131639903,
      "acc_norm,none": 0.6629166666666667,
      "acc_norm_stderr,none": 0.009651237099023628,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\Medium\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.5655241935483871,
      "acc_stderr,none": 0.01574604782985797,
      "acc_norm,none": 0.5514112903225806,
      "acc_norm_stderr,none": 0.01579883885000548,
      "n_samples_original": 992,
      "n_samples_effective": 992,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\Medium\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.47333333333333333,
      "acc_stderr,none": 0.012895869942232146,
      "acc_norm,none": 0.4693333333333333,
      "acc_norm_stderr,none": 0.012889936799075373,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\Medium\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.904,
      "acc_stderr,none": 0.018668961419477163,
      "acc_norm,none": 0.82,
      "acc_norm_stderr,none": 0.02434689065029353,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Medium\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752431769.7658036,
      "evaluation_time": "829.3948865570128",
      "acc,none": 0.7383333333333333,
      "acc_stderr,none": 0.008973984497330143,
      "acc_norm,none": 0.7329166666666667,
      "acc_norm_stderr,none": 0.009033074015690427,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Medium\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752431769.7658036,
      "evaluation_time": "829.3948865570128",
      "acc,none": 0.524,
      "acc_stderr,none": 0.015801065586651755,
      "acc_norm,none": 0.527,
      "acc_norm_stderr,none": 0.01579621855130262,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Medium\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752431769.7658036,
      "evaluation_time": "829.3948865570128",
      "acc,none": 0.6146666666666667,
      "acc_stderr,none": 0.012570058656192325,
      "acc_norm,none": 0.6626666666666666,
      "acc_norm_stderr,none": 0.01221170698805369,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Medium\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752431769.7658036,
      "evaluation_time": "829.3948865570128",
      "acc,none": 0.88,
      "acc_stderr,none": 0.020593600596839946,
      "acc_norm,none": 0.868,
      "acc_norm_stderr,none": 0.021450980824038103,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Medium\\Qwen3-8B.json",
      "date": 1752419140.5423734,
      "evaluation_time": "912.9916552146897",
      "acc,none": 0.7483333333333333,
      "acc_stderr,none": 0.008860235590600556,
      "acc_norm,none": 0.7695833333333333,
      "acc_norm_stderr,none": 0.008597449780109416,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Medium\\Qwen3-8B.json",
      "date": 1752419140.5423734,
      "evaluation_time": "912.9916552146897",
      "acc,none": 0.568,
      "acc_stderr,none": 0.015672320237336206,
      "acc_norm,none": 0.592,
      "acc_norm_stderr,none": 0.015549205052920673,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Medium\\Qwen3-8B.json",
      "date": 1752419140.5423734,
      "evaluation_time": "912.9916552146897",
      "acc,none": 0.692,
      "acc_stderr,none": 0.011924154350364261,
      "acc_norm,none": 0.74,
      "acc_norm_stderr,none": 0.01132926453143431,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Medium\\Qwen3-8B.json",
      "date": 1752419140.5423734,
      "evaluation_time": "912.9916552146897",
      "acc,none": 0.868,
      "acc_stderr,none": 0.0214509808240381,
      "acc_norm,none": 0.86,
      "acc_norm_stderr,none": 0.02198940964524027,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_all",
      "file_path": "Hypernymy\\Mixed\\Gemma-3-1b-it.json",
      "date": 1752451607.4470053,
      "evaluation_time": "1019.7617305275053",
      "acc,none": 0.3675,
      "acc_stderr,none": 0.00762400609045013,
      "acc_norm,none": 0.4005,
      "acc_norm_stderr,none": 0.0077485448625448615,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_all",
      "file_path": "Hypernymy\\Mixed\\Gemma-3-1b-it.json",
      "date": 1752451607.4470053,
      "evaluation_time": "1019.7617305275053",
      "acc,none": 0.4605,
      "acc_stderr,none": 0.007881971128291273,
      "acc_norm,none": 0.441,
      "acc_norm_stderr,none": 0.007851443261612752,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_all",
      "file_path": "Hypernymy\\Mixed\\Gemma-3-1b-it.json",
      "date": 1752451607.4470053,
      "evaluation_time": "1019.7617305275053",
      "acc,none": 0.4015,
      "acc_stderr,none": 0.007751739150988108,
      "acc_norm,none": 0.333,
      "acc_norm_stderr,none": 0.007452626074670165,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_all",
      "file_path": "Hypernymy\\Mixed\\Google-mt5-large.json",
      "date": 1752491637.2499845,
      "evaluation_time": "756.0853804536164",
      "acc,none": 0.2735,
      "acc_stderr,none": 0.007048890637171296,
      "acc_norm,none": 0.284,
      "acc_norm_stderr,none": 0.0071308282953694326,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_all",
      "file_path": "Hypernymy\\Mixed\\Google-mt5-large.json",
      "date": 1752491637.2499845,
      "evaluation_time": "756.0853804536164",
      "acc,none": 0.38625,
      "acc_stderr,none": 0.007699354153992134,
      "acc_norm,none": 0.293,
      "acc_norm_stderr,none": 0.007197270328051312,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_all",
      "file_path": "Hypernymy\\Mixed\\Google-mt5-large.json",
      "date": 1752491637.2499845,
      "evaluation_time": "756.0853804536164",
      "acc,none": 0.31875,
      "acc_stderr,none": 0.007368899819249652,
      "acc_norm,none": 0.2215,
      "acc_norm_stderr,none": 0.0065665986290004835,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_all",
      "file_path": "Hypernymy\\Mixed\\Llama-3.1-8B-Instruct.json",
      "date": 1752499548.6365058,
      "evaluation_time": "1899.3147991076112",
      "acc,none": 0.496,
      "acc_stderr,none": 0.007906429529628282,
      "acc_norm,none": 0.5095,
      "acc_norm_stderr,none": 0.007905255262493915,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_all",
      "file_path": "Hypernymy\\Mixed\\Llama-3.1-8B-Instruct.json",
      "date": 1752499548.6365058,
      "evaluation_time": "1899.3147991076112",
      "acc,none": 0.70075,
      "acc_stderr,none": 0.007241406553095682,
      "acc_norm,none": 0.69525,
      "acc_norm_stderr,none": 0.007278915099536364,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_all",
      "file_path": "Hypernymy\\Mixed\\Llama-3.1-8B-Instruct.json",
      "date": 1752499548.6365058,
      "evaluation_time": "1899.3147991076112",
      "acc,none": 0.5915,
      "acc_stderr,none": 0.007773161712633364,
      "acc_norm,none": 0.547,
      "acc_norm_stderr,none": 0.007871673317040202,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_all",
      "file_path": "Hypernymy\\Mixed\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752502396.6335452,
      "evaluation_time": "2042.99693417456",
      "acc,none": 0.44575,
      "acc_stderr,none": 0.007860005044198249,
      "acc_norm,none": 0.47275,
      "acc_norm_stderr,none": 0.00789493140315151,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_all",
      "file_path": "Hypernymy\\Mixed\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752502396.6335452,
      "evaluation_time": "2042.99693417456",
      "acc,none": 0.618,
      "acc_stderr,none": 0.007683342920865466,
      "acc_norm,none": 0.6025,
      "acc_norm_stderr,none": 0.0077387602109382425,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_all",
      "file_path": "Hypernymy\\Mixed\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752502396.6335452,
      "evaluation_time": "2042.99693417456",
      "acc,none": 0.50275,
      "acc_stderr,none": 0.007906562958040155,
      "acc_norm,none": 0.44775,
      "acc_norm_stderr,none": 0.00786339256368734,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_all",
      "file_path": "Hypernymy\\Mixed\\Qwen3-8B.json",
      "date": 1752489418.3087704,
      "evaluation_time": "2192.0517944255844",
      "acc,none": 0.46125,
      "acc_stderr,none": 0.007882902029779355,
      "acc_norm,none": 0.4875,
      "acc_norm_stderr,none": 0.00790421132303259,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_all",
      "file_path": "Hypernymy\\Mixed\\Qwen3-8B.json",
      "date": 1752489418.3087704,
      "evaluation_time": "2192.0517944255844",
      "acc,none": 0.6655,
      "acc_stderr,none": 0.0074609888143945605,
      "acc_norm,none": 0.67125,
      "acc_norm_stderr,none": 0.007428469217390986,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "meronymy_all",
      "file_path": "Hypernymy\\Mixed\\Qwen3-8B.json",
      "date": 1752489418.3087704,
      "evaluation_time": "2192.0517944255844",
      "acc,none": 0.543,
      "acc_stderr,none": 0.007877389371855838,
      "acc_norm,none": 0.51425,
      "acc_norm_stderr,none": 0.00790347079374944,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Monolingual_EN\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.61,
      "acc_stderr,none": 0.009958228723006411,
      "acc_norm,none": 0.63375,
      "acc_norm_stderr,none": 0.009836320676970411,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Monolingual_EN\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.405,
      "acc_stderr,none": 0.01553113699045304,
      "acc_norm,none": 0.402,
      "acc_norm_stderr,none": 0.015512467135715066,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Monolingual_EN\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.5353333333333333,
      "acc_stderr,none": 0.012881964150338793,
      "acc_norm,none": 0.5706666666666667,
      "acc_norm_stderr,none": 0.012784617545263777,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Monolingual_EN\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.808,
      "acc_stderr,none": 0.024960691989171998,
      "acc_norm,none": 0.812,
      "acc_norm_stderr,none": 0.0247603777277505,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\Monolingual_EN\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.5008333333333334,
      "acc_stderr,none": 0.010208320041221635,
      "acc_norm,none": 0.4870833333333333,
      "acc_norm_stderr,none": 0.01020492732833829,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\Monolingual_EN\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.3800403225806452,
      "acc_stderr,none": 0.015419125156073339,
      "acc_norm,none": 0.3639112903225806,
      "acc_norm_stderr,none": 0.015283393013872468,
      "n_samples_original": 992,
      "n_samples_effective": 992,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\Monolingual_EN\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.37133333333333335,
      "acc_stderr,none": 0.01247933285175456,
      "acc_norm,none": 0.4013333333333333,
      "acc_norm_stderr,none": 0.012660309957688232,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\Monolingual_EN\\Gemma-3-1b-it.json",
      "date": 1752442723.2802923,
      "evaluation_time": "870.2598905749619",
      "acc,none": 0.756,
      "acc_stderr,none": 0.027217995464553175,
      "acc_norm,none": 0.704,
      "acc_norm_stderr,none": 0.02892893938837963,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Monolingual_EN\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.4166666666666667,
      "acc_stderr,none": 0.0100655532824917,
      "acc_norm,none": 0.3129166666666667,
      "acc_norm_stderr,none": 0.00946681588039243,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Monolingual_EN\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.333,
      "acc_stderr,none": 0.01491084616422986,
      "acc_norm,none": 0.237,
      "acc_norm_stderr,none": 0.013454070462577966,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Monolingual_EN\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.37733333333333335,
      "acc_stderr,none": 0.012519574770236533,
      "acc_norm,none": 0.31866666666666665,
      "acc_norm_stderr,none": 0.01203503397765781,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Monolingual_EN\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.48,
      "acc_stderr,none": 0.031660853408495185,
      "acc_norm,none": 0.396,
      "acc_norm_stderr,none": 0.030993197854577853,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\Monolingual_EN\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.34375,
      "acc_stderr,none": 0.00969707797099156,
      "acc_norm,none": 0.22875,
      "acc_norm_stderr,none": 0.008575570386944793,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\Monolingual_EN\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.3004032258064516,
      "acc_stderr,none": 0.01456261499632924,
      "acc_norm,none": 0.22782258064516128,
      "acc_norm_stderr,none": 0.013323554568901394,
      "n_samples_original": 992,
      "n_samples_effective": 992,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\Monolingual_EN\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.30733333333333335,
      "acc_stderr,none": 0.011916978642131138,
      "acc_norm,none": 0.26,
      "acc_norm_stderr,none": 0.011329264531434308,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\Monolingual_EN\\Google-mt5-large.json",
      "date": 1752448885.5298862,
      "evaluation_time": "630.675122144632",
      "acc,none": 0.424,
      "acc_stderr,none": 0.03131803437491615,
      "acc_norm,none": 0.176,
      "acc_norm_stderr,none": 0.02413349752545711,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.7879166666666667,
      "acc_stderr,none": 0.008345998261206244,
      "acc_norm,none": 0.78,
      "acc_norm_stderr,none": 0.008457529431520559,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.658,
      "acc_stderr,none": 0.015008706182121726,
      "acc_norm,none": 0.667,
      "acc_norm_stderr,none": 0.014910846164229876,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.732,
      "acc_stderr,none": 0.01143989718040901,
      "acc_norm,none": 0.7833333333333333,
      "acc_norm_stderr,none": 0.010640659310800672,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.884,
      "acc_stderr,none": 0.02029342980308387,
      "acc_norm,none": 0.868,
      "acc_norm_stderr,none": 0.02145098082403809,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.70125,
      "acc_stderr,none": 0.0093449131639903,
      "acc_norm,none": 0.6629166666666667,
      "acc_norm_stderr,none": 0.009651237099023628,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.5655241935483871,
      "acc_stderr,none": 0.01574604782985797,
      "acc_norm,none": 0.5514112903225806,
      "acc_norm_stderr,none": 0.01579883885000548,
      "n_samples_original": 992,
      "n_samples_effective": 992,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.47333333333333333,
      "acc_stderr,none": 0.012895869942232146,
      "acc_norm,none": 0.4693333333333333,
      "acc_norm_stderr,none": 0.012889936799075373,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "date": 1752492511.6681714,
      "evaluation_time": "1439.5739394733682",
      "acc,none": 0.904,
      "acc_stderr,none": 0.018668961419477163,
      "acc_norm,none": 0.82,
      "acc_norm_stderr,none": 0.02434689065029353,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Monolingual_EN\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752431769.7658036,
      "evaluation_time": "829.3948865570128",
      "acc,none": 0.7383333333333333,
      "acc_stderr,none": 0.008973984497330143,
      "acc_norm,none": 0.7329166666666667,
      "acc_norm_stderr,none": 0.009033074015690427,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Monolingual_EN\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752431769.7658036,
      "evaluation_time": "829.3948865570128",
      "acc,none": 0.524,
      "acc_stderr,none": 0.015801065586651755,
      "acc_norm,none": 0.527,
      "acc_norm_stderr,none": 0.01579621855130262,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Monolingual_EN\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752431769.7658036,
      "evaluation_time": "829.3948865570128",
      "acc,none": 0.6146666666666667,
      "acc_stderr,none": 0.012570058656192325,
      "acc_norm,none": 0.6626666666666666,
      "acc_norm_stderr,none": 0.01221170698805369,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Monolingual_EN\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752431769.7658036,
      "evaluation_time": "829.3948865570128",
      "acc,none": 0.88,
      "acc_stderr,none": 0.020593600596839946,
      "acc_norm,none": 0.868,
      "acc_norm_stderr,none": 0.021450980824038103,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Monolingual_EN\\Qwen3-8B.json",
      "date": 1752419140.5423734,
      "evaluation_time": "912.9916552146897",
      "acc,none": 0.7483333333333333,
      "acc_stderr,none": 0.008860235590600556,
      "acc_norm,none": 0.7695833333333333,
      "acc_norm_stderr,none": 0.008597449780109416,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Monolingual_EN\\Qwen3-8B.json",
      "date": 1752419140.5423734,
      "evaluation_time": "912.9916552146897",
      "acc,none": 0.568,
      "acc_stderr,none": 0.015672320237336206,
      "acc_norm,none": 0.592,
      "acc_norm_stderr,none": 0.015549205052920673,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Monolingual_EN\\Qwen3-8B.json",
      "date": 1752419140.5423734,
      "evaluation_time": "912.9916552146897",
      "acc,none": 0.692,
      "acc_stderr,none": 0.011924154350364261,
      "acc_norm,none": 0.74,
      "acc_norm_stderr,none": 0.01132926453143431,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Monolingual_EN\\Qwen3-8B.json",
      "date": 1752419140.5423734,
      "evaluation_time": "912.9916552146897",
      "acc,none": 0.868,
      "acc_stderr,none": 0.0214509808240381,
      "acc_norm,none": 0.86,
      "acc_norm_stderr,none": 0.02198940964524027,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    }
  ],
  "model_configs": [
    {
      "model_name": "google/gemma-3-1b-it",
      "file_path": "Hypernymy\\High\\Gemma-3-1b-it.json",
      "model": "hf",
      "model_args": "pretrained=google/gemma-3-1b-it",
      "model_num_parameters": 999885952,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "dcc83ea841ab6100d6b47a070329e1ba4cf78752",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "google/mt5-large",
      "file_path": "Hypernymy\\High\\Google-mt5-large.json",
      "model": "hf",
      "model_args": "pretrained=google/mt5-large,use_safetensors=True",
      "model_num_parameters": 1229581312,
      "model_dtype": "torch.float32",
      "model_revision": "main",
      "model_sha": "50b7223e98fcd124b0cabb1ec81bc6324c7df107",
      "batch_size": "4",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "file_path": "Hypernymy\\High\\Llama-3.1-8B-Instruct.json",
      "model": "hf",
      "model_args": "pretrained=meta-llama/Llama-3.1-8B-Instruct",
      "model_num_parameters": 8030261248,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "0e9e39f249a16976918f6564b8830bc894c89659",
      "batch_size": "4",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "file_path": "Hypernymy\\High\\Mistral-7B-Instruct-v0.3.json",
      "model": "hf",
      "model_args": "pretrained=mistralai/Mistral-7B-Instruct-v0.3",
      "model_num_parameters": 7248023552,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "e0bc86c23ce5aae1db576c8cca6f06f1f73af2db",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "file_path": "Hypernymy\\High\\Qwen3-8B.json",
      "model": "hf",
      "model_args": "pretrained=Qwen/Qwen3-8B",
      "model_num_parameters": 8190735360,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "9c925d64d72725edaf899c6cb9c377fd0709d9c5",
      "batch_size": "1",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "file_path": "Hypernymy\\Low\\Gemma-3-1b-it.json",
      "model": "hf",
      "model_args": "pretrained=google/gemma-3-1b-it",
      "model_num_parameters": 999885952,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "dcc83ea841ab6100d6b47a070329e1ba4cf78752",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "google/mt5-large",
      "file_path": "Hypernymy\\Low\\Google-mt5-large.json",
      "model": "hf",
      "model_args": "pretrained=google/mt5-large,use_safetensors=True",
      "model_num_parameters": 1229581312,
      "model_dtype": "torch.float32",
      "model_revision": "main",
      "model_sha": "50b7223e98fcd124b0cabb1ec81bc6324c7df107",
      "batch_size": "4",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "file_path": "Hypernymy\\Low\\Llama-3.1-8B-Instruct.json",
      "model": "hf",
      "model_args": "pretrained=meta-llama/Llama-3.1-8B-Instruct",
      "model_num_parameters": 8030261248,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "0e9e39f249a16976918f6564b8830bc894c89659",
      "batch_size": "4",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "file_path": "Hypernymy\\Low\\Mistral-7B-Instruct-v0.3.json",
      "model": "hf",
      "model_args": "pretrained=mistralai/Mistral-7B-Instruct-v0.3",
      "model_num_parameters": 7248023552,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "e0bc86c23ce5aae1db576c8cca6f06f1f73af2db",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "file_path": "Hypernymy\\Low\\Qwen3-8B.json",
      "model": "hf",
      "model_args": "pretrained=Qwen/Qwen3-8B",
      "model_num_parameters": 8190735360,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "9c925d64d72725edaf899c6cb9c377fd0709d9c5",
      "batch_size": "1",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "file_path": "Hypernymy\\Medium\\Gemma-3-1b-it.json",
      "model": "hf",
      "model_args": "pretrained=google/gemma-3-1b-it",
      "model_num_parameters": 999885952,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "dcc83ea841ab6100d6b47a070329e1ba4cf78752",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "google/mt5-large",
      "file_path": "Hypernymy\\Medium\\Google-mt5-large.json",
      "model": "hf",
      "model_args": "pretrained=google/mt5-large,use_safetensors=True",
      "model_num_parameters": 1229581312,
      "model_dtype": "torch.float32",
      "model_revision": "main",
      "model_sha": "50b7223e98fcd124b0cabb1ec81bc6324c7df107",
      "batch_size": "4",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "file_path": "Hypernymy\\Medium\\Llama-3.1-8B-Instruct.json",
      "model": "hf",
      "model_args": "pretrained=meta-llama/Llama-3.1-8B-Instruct",
      "model_num_parameters": 8030261248,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "0e9e39f249a16976918f6564b8830bc894c89659",
      "batch_size": "4",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "file_path": "Hypernymy\\Medium\\Mistral-7B-Instruct-v0.3.json",
      "model": "hf",
      "model_args": "pretrained=mistralai/Mistral-7B-Instruct-v0.3",
      "model_num_parameters": 7248023552,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "e0bc86c23ce5aae1db576c8cca6f06f1f73af2db",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "file_path": "Hypernymy\\Medium\\Qwen3-8B.json",
      "model": "hf",
      "model_args": "pretrained=Qwen/Qwen3-8B",
      "model_num_parameters": 8190735360,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "9c925d64d72725edaf899c6cb9c377fd0709d9c5",
      "batch_size": "1",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "file_path": "Hypernymy\\Mixed\\Gemma-3-1b-it.json",
      "model": "hf",
      "model_args": "pretrained=google/gemma-3-1b-it",
      "model_num_parameters": 999885952,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "dcc83ea841ab6100d6b47a070329e1ba4cf78752",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "google/mt5-large",
      "file_path": "Hypernymy\\Mixed\\Google-mt5-large.json",
      "model": "hf",
      "model_args": "pretrained=google/mt5-large,use_safetensors=True",
      "model_num_parameters": 1229581312,
      "model_dtype": "torch.float32",
      "model_revision": "main",
      "model_sha": "50b7223e98fcd124b0cabb1ec81bc6324c7df107",
      "batch_size": "4",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "file_path": "Hypernymy\\Mixed\\Llama-3.1-8B-Instruct.json",
      "model": "hf",
      "model_args": "pretrained=meta-llama/Llama-3.1-8B-Instruct",
      "model_num_parameters": 8030261248,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "0e9e39f249a16976918f6564b8830bc894c89659",
      "batch_size": "4",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "file_path": "Hypernymy\\Mixed\\Mistral-7B-Instruct-v0.3.json",
      "model": "hf",
      "model_args": "pretrained=mistralai/Mistral-7B-Instruct-v0.3",
      "model_num_parameters": 7248023552,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "e0bc86c23ce5aae1db576c8cca6f06f1f73af2db",
      "batch_size": "4",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "file_path": "Hypernymy\\Mixed\\Qwen3-8B.json",
      "model": "hf",
      "model_args": "pretrained=Qwen/Qwen3-8B",
      "model_num_parameters": 8190735360,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "9c925d64d72725edaf899c6cb9c377fd0709d9c5",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "file_path": "Hypernymy\\Monolingual_EN\\Gemma-3-1b-it.json",
      "model": "hf",
      "model_args": "pretrained=google/gemma-3-1b-it",
      "model_num_parameters": 999885952,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "dcc83ea841ab6100d6b47a070329e1ba4cf78752",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "google/mt5-large",
      "file_path": "Hypernymy\\Monolingual_EN\\Google-mt5-large.json",
      "model": "hf",
      "model_args": "pretrained=google/mt5-large,use_safetensors=True",
      "model_num_parameters": 1229581312,
      "model_dtype": "torch.float32",
      "model_revision": "main",
      "model_sha": "50b7223e98fcd124b0cabb1ec81bc6324c7df107",
      "batch_size": "4",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "file_path": "Hypernymy\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "model": "hf",
      "model_args": "pretrained=meta-llama/Llama-3.1-8B-Instruct",
      "model_num_parameters": 8030261248,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "0e9e39f249a16976918f6564b8830bc894c89659",
      "batch_size": "4",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "file_path": "Hypernymy\\Monolingual_EN\\Mistral-7B-Instruct-v0.3.json",
      "model": "hf",
      "model_args": "pretrained=mistralai/Mistral-7B-Instruct-v0.3",
      "model_num_parameters": 7248023552,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "e0bc86c23ce5aae1db576c8cca6f06f1f73af2db",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "file_path": "Hypernymy\\Monolingual_EN\\Qwen3-8B.json",
      "model": "hf",
      "model_args": "pretrained=Qwen/Qwen3-8B",
      "model_num_parameters": 8190735360,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "9c925d64d72725edaf899c6cb9c377fd0709d9c5",
      "batch_size": "1",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    }
  ],
  "task_configs": [
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\High\\Gemma-3-1b-it.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\High\\Gemma-3-1b-it.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\High\\Gemma-3-1b-it.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\High\\Gemma-3-1b-it.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\High\\Gemma-3-1b-it.json",
      "task": "meronymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_high",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\High\\Gemma-3-1b-it.json",
      "task": "meronymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_low",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\High\\Gemma-3-1b-it.json",
      "task": "meronymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_medium",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\High\\Gemma-3-1b-it.json",
      "task": "meronymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_mono",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\High\\Google-mt5-large.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\High\\Google-mt5-large.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\High\\Google-mt5-large.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\High\\Google-mt5-large.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\High\\Google-mt5-large.json",
      "task": "meronymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_high",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\High\\Google-mt5-large.json",
      "task": "meronymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_low",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\High\\Google-mt5-large.json",
      "task": "meronymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_medium",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\High\\Google-mt5-large.json",
      "task": "meronymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_mono",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\High\\Llama-3.1-8B-Instruct.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\High\\Llama-3.1-8B-Instruct.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\High\\Llama-3.1-8B-Instruct.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\High\\Llama-3.1-8B-Instruct.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\High\\Llama-3.1-8B-Instruct.json",
      "task": "meronymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_high",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\High\\Llama-3.1-8B-Instruct.json",
      "task": "meronymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_low",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\High\\Llama-3.1-8B-Instruct.json",
      "task": "meronymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_medium",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\High\\Llama-3.1-8B-Instruct.json",
      "task": "meronymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_mono",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\High\\Mistral-7B-Instruct-v0.3.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\High\\Mistral-7B-Instruct-v0.3.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\High\\Mistral-7B-Instruct-v0.3.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\High\\Mistral-7B-Instruct-v0.3.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\High\\Qwen3-8B.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\High\\Qwen3-8B.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\High\\Qwen3-8B.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\High\\Qwen3-8B.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Low\\Gemma-3-1b-it.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Low\\Gemma-3-1b-it.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Low\\Gemma-3-1b-it.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Low\\Gemma-3-1b-it.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\Low\\Gemma-3-1b-it.json",
      "task": "meronymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_high",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\Low\\Gemma-3-1b-it.json",
      "task": "meronymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_low",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\Low\\Gemma-3-1b-it.json",
      "task": "meronymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_medium",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\Low\\Gemma-3-1b-it.json",
      "task": "meronymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_mono",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Low\\Google-mt5-large.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Low\\Google-mt5-large.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Low\\Google-mt5-large.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Low\\Google-mt5-large.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\Low\\Google-mt5-large.json",
      "task": "meronymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_high",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\Low\\Google-mt5-large.json",
      "task": "meronymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_low",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\Low\\Google-mt5-large.json",
      "task": "meronymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_medium",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\Low\\Google-mt5-large.json",
      "task": "meronymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_mono",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Low\\Llama-3.1-8B-Instruct.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Low\\Llama-3.1-8B-Instruct.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Low\\Llama-3.1-8B-Instruct.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Low\\Llama-3.1-8B-Instruct.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\Low\\Llama-3.1-8B-Instruct.json",
      "task": "meronymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_high",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\Low\\Llama-3.1-8B-Instruct.json",
      "task": "meronymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_low",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\Low\\Llama-3.1-8B-Instruct.json",
      "task": "meronymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_medium",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\Low\\Llama-3.1-8B-Instruct.json",
      "task": "meronymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_mono",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Low\\Mistral-7B-Instruct-v0.3.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Low\\Mistral-7B-Instruct-v0.3.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Low\\Mistral-7B-Instruct-v0.3.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Low\\Mistral-7B-Instruct-v0.3.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Low\\Qwen3-8B.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Low\\Qwen3-8B.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Low\\Qwen3-8B.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Low\\Qwen3-8B.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Medium\\Gemma-3-1b-it.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Medium\\Gemma-3-1b-it.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Medium\\Gemma-3-1b-it.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Medium\\Gemma-3-1b-it.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\Medium\\Gemma-3-1b-it.json",
      "task": "meronymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_high",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\Medium\\Gemma-3-1b-it.json",
      "task": "meronymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_low",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\Medium\\Gemma-3-1b-it.json",
      "task": "meronymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_medium",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\Medium\\Gemma-3-1b-it.json",
      "task": "meronymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_mono",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Medium\\Google-mt5-large.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Medium\\Google-mt5-large.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Medium\\Google-mt5-large.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Medium\\Google-mt5-large.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\Medium\\Google-mt5-large.json",
      "task": "meronymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_high",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\Medium\\Google-mt5-large.json",
      "task": "meronymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_low",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\Medium\\Google-mt5-large.json",
      "task": "meronymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_medium",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\Medium\\Google-mt5-large.json",
      "task": "meronymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_mono",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Medium\\Llama-3.1-8B-Instruct.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Medium\\Llama-3.1-8B-Instruct.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Medium\\Llama-3.1-8B-Instruct.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Medium\\Llama-3.1-8B-Instruct.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\Medium\\Llama-3.1-8B-Instruct.json",
      "task": "meronymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_high",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\Medium\\Llama-3.1-8B-Instruct.json",
      "task": "meronymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_low",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\Medium\\Llama-3.1-8B-Instruct.json",
      "task": "meronymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_medium",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\Medium\\Llama-3.1-8B-Instruct.json",
      "task": "meronymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_mono",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Medium\\Mistral-7B-Instruct-v0.3.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Medium\\Mistral-7B-Instruct-v0.3.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Medium\\Mistral-7B-Instruct-v0.3.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Medium\\Mistral-7B-Instruct-v0.3.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Medium\\Qwen3-8B.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Medium\\Qwen3-8B.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Medium\\Qwen3-8B.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Medium\\Qwen3-8B.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_all",
      "file_path": "Hypernymy\\Mixed\\Gemma-3-1b-it.json",
      "task": "analogies_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_all",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_all",
      "file_path": "Hypernymy\\Mixed\\Gemma-3-1b-it.json",
      "task": "hypernymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_all",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_all",
      "file_path": "Hypernymy\\Mixed\\Gemma-3-1b-it.json",
      "task": "meronymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_all",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_all",
      "file_path": "Hypernymy\\Mixed\\Google-mt5-large.json",
      "task": "analogies_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_all",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_all",
      "file_path": "Hypernymy\\Mixed\\Google-mt5-large.json",
      "task": "hypernymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_all",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_all",
      "file_path": "Hypernymy\\Mixed\\Google-mt5-large.json",
      "task": "meronymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_all",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_all",
      "file_path": "Hypernymy\\Mixed\\Llama-3.1-8B-Instruct.json",
      "task": "analogies_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_all",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_all",
      "file_path": "Hypernymy\\Mixed\\Llama-3.1-8B-Instruct.json",
      "task": "hypernymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_all",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_all",
      "file_path": "Hypernymy\\Mixed\\Llama-3.1-8B-Instruct.json",
      "task": "meronymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_all",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_all",
      "file_path": "Hypernymy\\Mixed\\Mistral-7B-Instruct-v0.3.json",
      "task": "analogies_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_all",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_all",
      "file_path": "Hypernymy\\Mixed\\Mistral-7B-Instruct-v0.3.json",
      "task": "hypernymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_all",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_all",
      "file_path": "Hypernymy\\Mixed\\Mistral-7B-Instruct-v0.3.json",
      "task": "meronymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_all",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_all",
      "file_path": "Hypernymy\\Mixed\\Qwen3-8B.json",
      "task": "analogies_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_all",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_all",
      "file_path": "Hypernymy\\Mixed\\Qwen3-8B.json",
      "task": "hypernymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_all",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "meronymy_all",
      "file_path": "Hypernymy\\Mixed\\Qwen3-8B.json",
      "task": "meronymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_all",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Monolingual_EN\\Gemma-3-1b-it.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Monolingual_EN\\Gemma-3-1b-it.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Monolingual_EN\\Gemma-3-1b-it.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Monolingual_EN\\Gemma-3-1b-it.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\Monolingual_EN\\Gemma-3-1b-it.json",
      "task": "meronymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_high",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\Monolingual_EN\\Gemma-3-1b-it.json",
      "task": "meronymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_low",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\Monolingual_EN\\Gemma-3-1b-it.json",
      "task": "meronymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_medium",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\Monolingual_EN\\Gemma-3-1b-it.json",
      "task": "meronymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_mono",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Monolingual_EN\\Google-mt5-large.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Monolingual_EN\\Google-mt5-large.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Monolingual_EN\\Google-mt5-large.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Monolingual_EN\\Google-mt5-large.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\Monolingual_EN\\Google-mt5-large.json",
      "task": "meronymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_high",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\Monolingual_EN\\Google-mt5-large.json",
      "task": "meronymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_low",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\Monolingual_EN\\Google-mt5-large.json",
      "task": "meronymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_medium",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\Monolingual_EN\\Google-mt5-large.json",
      "task": "meronymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_mono",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_high",
      "file_path": "Hypernymy\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "task": "meronymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_high",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_low",
      "file_path": "Hypernymy\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "task": "meronymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_low",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_medium",
      "file_path": "Hypernymy\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "task": "meronymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_medium",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_mono",
      "file_path": "Hypernymy\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "task": "meronymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_mono",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Monolingual_EN\\Mistral-7B-Instruct-v0.3.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Monolingual_EN\\Mistral-7B-Instruct-v0.3.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Monolingual_EN\\Mistral-7B-Instruct-v0.3.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Monolingual_EN\\Mistral-7B-Instruct-v0.3.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_high",
      "file_path": "Hypernymy\\Monolingual_EN\\Qwen3-8B.json",
      "task": "hypernymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_high",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_low",
      "file_path": "Hypernymy\\Monolingual_EN\\Qwen3-8B.json",
      "task": "hypernymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_low",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_medium",
      "file_path": "Hypernymy\\Monolingual_EN\\Qwen3-8B.json",
      "task": "hypernymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_medium",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_mono",
      "file_path": "Hypernymy\\Monolingual_EN\\Qwen3-8B.json",
      "task": "hypernymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_mono",
        "pretrained": "Qwen/Qwen3-8B"
      }
    }
  ],
  "duplicates_found": []
}