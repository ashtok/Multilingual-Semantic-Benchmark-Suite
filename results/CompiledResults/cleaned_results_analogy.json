{
  "timestamp": "20250715_114244",
  "results": [
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_high",
      "file_path": "Analogies\\High\\Gemma-3-1b-it.json",
      "date": 1752421223.8075268,
      "evaluation_time": "830.5526526710019",
      "acc,none": 0.4091666666666667,
      "acc_stderr,none": 0.010038469264549542,
      "acc_norm,none": 0.44,
      "acc_norm_stderr,none": 0.010134567690629278,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_low",
      "file_path": "Analogies\\High\\Gemma-3-1b-it.json",
      "date": 1752421223.8075268,
      "evaluation_time": "830.5526526710019",
      "acc,none": 0.339,
      "acc_stderr,none": 0.01497675877162035,
      "acc_norm,none": 0.333,
      "acc_norm_stderr,none": 0.014910846164229859,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\High\\Gemma-3-1b-it.json",
      "date": 1752421223.8075268,
      "evaluation_time": "830.5526526710019",
      "acc,none": 0.37133333333333335,
      "acc_stderr,none": 0.01247933285175456,
      "acc_norm,none": 0.4053333333333333,
      "acc_norm_stderr,none": 0.012680668267614695,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\High\\Gemma-3-1b-it.json",
      "date": 1752421223.8075268,
      "evaluation_time": "830.5526526710019",
      "acc,none": 0.5375,
      "acc_stderr,none": 0.024960808880119843,
      "acc_norm,none": 0.5475,
      "acc_norm_stderr,none": 0.024918098926991643,
      "n_samples_original": 400,
      "n_samples_effective": 400,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_high",
      "file_path": "Analogies\\High\\Google-mt5-large.json",
      "date": 1752446583.3220806,
      "evaluation_time": "567.9101229580119",
      "acc,none": 0.3045833333333333,
      "acc_stderr,none": 0.009396378254261456,
      "acc_norm,none": 0.2654166666666667,
      "acc_norm_stderr,none": 0.009015078372747957,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_low",
      "file_path": "Analogies\\High\\Google-mt5-large.json",
      "date": 1752446583.3220806,
      "evaluation_time": "567.9101229580119",
      "acc,none": 0.294,
      "acc_stderr,none": 0.014414290540008213,
      "acc_norm,none": 0.267,
      "acc_norm_stderr,none": 0.013996674851796282,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\High\\Google-mt5-large.json",
      "date": 1752446583.3220806,
      "evaluation_time": "567.9101229580119",
      "acc,none": 0.30733333333333335,
      "acc_stderr,none": 0.011916978642131138,
      "acc_norm,none": 0.26,
      "acc_norm_stderr,none": 0.011329264531434308,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\High\\Google-mt5-large.json",
      "date": 1752446583.3220806,
      "evaluation_time": "567.9101229580119",
      "acc,none": 0.3025,
      "acc_stderr,none": 0.022995790723031092,
      "acc_norm,none": 0.255,
      "acc_norm_stderr,none": 0.021820353332356286,
      "n_samples_original": 400,
      "n_samples_effective": 400,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_high",
      "file_path": "Analogies\\High\\Llama-3.1-8B-Instruct.json",
      "date": 1752447197.159415,
      "evaluation_time": "1407.9604069255292",
      "acc,none": 0.5204166666666666,
      "acc_stderr,none": 0.010199820179254564,
      "acc_norm,none": 0.5158333333333334,
      "acc_norm_stderr,none": 0.01020321459033726,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_low",
      "file_path": "Analogies\\High\\Llama-3.1-8B-Instruct.json",
      "date": 1752447197.159415,
      "evaluation_time": "1407.9604069255292",
      "acc,none": 0.435,
      "acc_stderr,none": 0.015685057252717197,
      "acc_norm,none": 0.422,
      "acc_norm_stderr,none": 0.015625625112620663,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\High\\Llama-3.1-8B-Instruct.json",
      "date": 1752447197.159415,
      "evaluation_time": "1407.9604069255292",
      "acc,none": 0.4706666666666667,
      "acc_stderr,none": 0.012892006810297882,
      "acc_norm,none": 0.4673333333333333,
      "acc_norm_stderr,none": 0.012886658601277011,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\High\\Llama-3.1-8B-Instruct.json",
      "date": 1752447197.159415,
      "evaluation_time": "1407.9604069255292",
      "acc,none": 0.775,
      "acc_stderr,none": 0.020905264293664554,
      "acc_norm,none": 0.68,
      "acc_norm_stderr,none": 0.02335301711816499,
      "n_samples_original": 400,
      "n_samples_effective": 400,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_high",
      "file_path": "Analogies\\High\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752443686.0157306,
      "evaluation_time": "1709.0482957325876",
      "acc,none": 0.49125,
      "acc_stderr,none": 0.010206770948599035,
      "acc_norm,none": 0.4970833333333333,
      "acc_norm_stderr,none": 0.010208160534531878,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_low",
      "file_path": "Analogies\\High\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752443686.0157306,
      "evaluation_time": "1709.0482957325876",
      "acc,none": 0.389,
      "acc_stderr,none": 0.015424555647308495,
      "acc_norm,none": 0.385,
      "acc_norm_stderr,none": 0.015395194445410808,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\High\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752443686.0157306,
      "evaluation_time": "1709.0482957325876",
      "acc,none": 0.4166666666666667,
      "acc_stderr,none": 0.012733622178818382,
      "acc_norm,none": 0.416,
      "acc_norm_stderr,none": 0.012730699659060487,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\High\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752443686.0157306,
      "evaluation_time": "1709.0482957325876",
      "acc,none": 0.7225,
      "acc_stderr,none": 0.022416302137144645,
      "acc_norm,none": 0.655,
      "acc_norm_stderr,none": 0.023798180255192706,
      "n_samples_original": 400,
      "n_samples_effective": 400,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_high",
      "file_path": "Analogies\\High\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752443686.0157306,
      "evaluation_time": "1709.0482957325876",
      "acc,none": 0.6629166666666667,
      "acc_stderr,none": 0.009651237099023624,
      "acc_norm,none": 0.6266666666666667,
      "acc_norm_stderr,none": 0.009875328637384974,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_low",
      "file_path": "Analogies\\High\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752443686.0157306,
      "evaluation_time": "1709.0482957325876",
      "acc,none": 0.5151209677419355,
      "acc_stderr,none": 0.015875758682922167,
      "acc_norm,none": 0.4848790322580645,
      "acc_norm_stderr,none": 0.015875758682922167,
      "n_samples_original": 992,
      "n_samples_effective": 992,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_medium",
      "file_path": "Analogies\\High\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752443686.0157306,
      "evaluation_time": "1709.0482957325876",
      "acc,none": 0.4166666666666667,
      "acc_stderr,none": 0.012733622178818382,
      "acc_norm,none": 0.416,
      "acc_norm_stderr,none": 0.012730699659060487,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_mono",
      "file_path": "Analogies\\High\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752443686.0157306,
      "evaluation_time": "1709.0482957325876",
      "acc,none": 0.892,
      "acc_stderr,none": 0.019669559381568752,
      "acc_norm,none": 0.848,
      "acc_norm_stderr,none": 0.022752024491765468,
      "n_samples_original": 250,
      "n_samples_effective": 250,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_high",
      "file_path": "Analogies\\High\\Qwen3-8B.json",
      "date": 1752416697.5706363,
      "evaluation_time": "1214.3463006140664",
      "acc,none": 0.49125,
      "acc_stderr,none": 0.010206770948599028,
      "acc_norm,none": 0.485,
      "acc_norm_stderr,none": 0.010203739435015534,
      "n_samples_original": 2400,
      "n_samples_effective": 2400,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_low",
      "file_path": "Analogies\\High\\Qwen3-8B.json",
      "date": 1752416697.5706363,
      "evaluation_time": "1214.3463006140664",
      "acc,none": 0.406,
      "acc_stderr,none": 0.015537226438634595,
      "acc_norm,none": 0.397,
      "acc_norm_stderr,none": 0.015480007449307989,
      "n_samples_original": 1000,
      "n_samples_effective": 1000,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\High\\Qwen3-8B.json",
      "date": 1752416697.5706363,
      "evaluation_time": "1214.3463006140664",
      "acc,none": 0.45,
      "acc_stderr,none": 0.012849516464920127,
      "acc_norm,none": 0.46,
      "acc_norm_stderr,none": 0.01287285802178749,
      "n_samples_original": 1500,
      "n_samples_effective": 1500,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\High\\Qwen3-8B.json",
      "date": 1752416697.5706363,
      "evaluation_time": "1214.3463006140664",
      "acc,none": 0.6875,
      "acc_stderr,none": 0.023204644228784484,
      "acc_norm,none": 0.65,
      "acc_norm_stderr,none": 0.023878346647045995,
      "n_samples_original": 400,
      "n_samples_effective": 400,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_all",
      "file_path": "Analogies\\Mixed\\Gemma-3-1b-it.json",
      "date": 1752451607.4470053,
      "evaluation_time": "1019.7617305275053",
      "acc,none": 0.3675,
      "acc_stderr,none": 0.00762400609045013,
      "acc_norm,none": 0.4005,
      "acc_norm_stderr,none": 0.0077485448625448615,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_all",
      "file_path": "Analogies\\Mixed\\Gemma-3-1b-it.json",
      "date": 1752451607.4470053,
      "evaluation_time": "1019.7617305275053",
      "acc,none": 0.4605,
      "acc_stderr,none": 0.007881971128291273,
      "acc_norm,none": 0.441,
      "acc_norm_stderr,none": 0.007851443261612752,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_all",
      "file_path": "Analogies\\Mixed\\Gemma-3-1b-it.json",
      "date": 1752451607.4470053,
      "evaluation_time": "1019.7617305275053",
      "acc,none": 0.4015,
      "acc_stderr,none": 0.007751739150988108,
      "acc_norm,none": 0.333,
      "acc_norm_stderr,none": 0.007452626074670165,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_all",
      "file_path": "Analogies\\Mixed\\Google-mt5-large.json",
      "date": 1752491637.2499845,
      "evaluation_time": "756.0853804536164",
      "acc,none": 0.2735,
      "acc_stderr,none": 0.007048890637171296,
      "acc_norm,none": 0.284,
      "acc_norm_stderr,none": 0.0071308282953694326,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_all",
      "file_path": "Analogies\\Mixed\\Google-mt5-large.json",
      "date": 1752491637.2499845,
      "evaluation_time": "756.0853804536164",
      "acc,none": 0.38625,
      "acc_stderr,none": 0.007699354153992134,
      "acc_norm,none": 0.293,
      "acc_norm_stderr,none": 0.007197270328051312,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_all",
      "file_path": "Analogies\\Mixed\\Google-mt5-large.json",
      "date": 1752491637.2499845,
      "evaluation_time": "756.0853804536164",
      "acc,none": 0.31875,
      "acc_stderr,none": 0.007368899819249652,
      "acc_norm,none": 0.2215,
      "acc_norm_stderr,none": 0.0065665986290004835,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_all",
      "file_path": "Analogies\\Mixed\\Llama-3.1-8B-Instruct.json",
      "date": 1752499548.6365058,
      "evaluation_time": "1899.3147991076112",
      "acc,none": 0.496,
      "acc_stderr,none": 0.007906429529628282,
      "acc_norm,none": 0.5095,
      "acc_norm_stderr,none": 0.007905255262493915,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_all",
      "file_path": "Analogies\\Mixed\\Llama-3.1-8B-Instruct.json",
      "date": 1752499548.6365058,
      "evaluation_time": "1899.3147991076112",
      "acc,none": 0.70075,
      "acc_stderr,none": 0.007241406553095682,
      "acc_norm,none": 0.69525,
      "acc_norm_stderr,none": 0.007278915099536364,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_all",
      "file_path": "Analogies\\Mixed\\Llama-3.1-8B-Instruct.json",
      "date": 1752499548.6365058,
      "evaluation_time": "1899.3147991076112",
      "acc,none": 0.5915,
      "acc_stderr,none": 0.007773161712633364,
      "acc_norm,none": 0.547,
      "acc_norm_stderr,none": 0.007871673317040202,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_all",
      "file_path": "Analogies\\Mixed\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752502396.6335452,
      "evaluation_time": "2042.99693417456",
      "acc,none": 0.44575,
      "acc_stderr,none": 0.007860005044198249,
      "acc_norm,none": 0.47275,
      "acc_norm_stderr,none": 0.00789493140315151,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_all",
      "file_path": "Analogies\\Mixed\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752502396.6335452,
      "evaluation_time": "2042.99693417456",
      "acc,none": 0.618,
      "acc_stderr,none": 0.007683342920865466,
      "acc_norm,none": 0.6025,
      "acc_norm_stderr,none": 0.0077387602109382425,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_all",
      "file_path": "Analogies\\Mixed\\Mistral-7B-Instruct-v0.3.json",
      "date": 1752502396.6335452,
      "evaluation_time": "2042.99693417456",
      "acc,none": 0.50275,
      "acc_stderr,none": 0.007906562958040155,
      "acc_norm,none": 0.44775,
      "acc_norm_stderr,none": 0.00786339256368734,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_all",
      "file_path": "Analogies\\Mixed\\Qwen3-8B.json",
      "date": 1752489418.3087704,
      "evaluation_time": "2192.0517944255844",
      "acc,none": 0.46125,
      "acc_stderr,none": 0.007882902029779355,
      "acc_norm,none": 0.4875,
      "acc_norm_stderr,none": 0.00790421132303259,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_all",
      "file_path": "Analogies\\Mixed\\Qwen3-8B.json",
      "date": 1752489418.3087704,
      "evaluation_time": "2192.0517944255844",
      "acc,none": 0.6655,
      "acc_stderr,none": 0.0074609888143945605,
      "acc_norm,none": 0.67125,
      "acc_norm_stderr,none": 0.007428469217390986,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "meronymy_all",
      "file_path": "Analogies\\Mixed\\Qwen3-8B.json",
      "date": 1752489418.3087704,
      "evaluation_time": "2192.0517944255844",
      "acc,none": 0.543,
      "acc_stderr,none": 0.007877389371855838,
      "acc_norm,none": 0.51425,
      "acc_norm_stderr,none": 0.00790347079374944,
      "n_samples_original": 4000,
      "n_samples_effective": 4000,
      "n_shot": 5
    }
  ],
  "model_configs": [
    {
      "model_name": "google/gemma-3-1b-it",
      "file_path": "Analogies\\High\\Gemma-3-1b-it.json",
      "model": "hf",
      "model_args": "pretrained=google/gemma-3-1b-it",
      "model_num_parameters": 999885952,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "dcc83ea841ab6100d6b47a070329e1ba4cf78752",
      "batch_size": "1",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "google/mt5-large",
      "file_path": "Analogies\\High\\Google-mt5-large.json",
      "model": "hf",
      "model_args": "pretrained=google/mt5-large,use_safetensors=True",
      "model_num_parameters": 1229581312,
      "model_dtype": "torch.float32",
      "model_revision": "main",
      "model_sha": "50b7223e98fcd124b0cabb1ec81bc6324c7df107",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "file_path": "Analogies\\High\\Llama-3.1-8B-Instruct.json",
      "model": "hf",
      "model_args": "pretrained=meta-llama/Llama-3.1-8B-Instruct",
      "model_num_parameters": 8030261248,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "0e9e39f249a16976918f6564b8830bc894c89659",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "file_path": "Analogies\\High\\Mistral-7B-Instruct-v0.3.json",
      "model": "hf",
      "model_args": "pretrained=mistralai/Mistral-7B-Instruct-v0.3",
      "model_num_parameters": 7248023552,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "e0bc86c23ce5aae1db576c8cca6f06f1f73af2db",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "file_path": "Analogies\\High\\Qwen3-8B.json",
      "model": "hf",
      "model_args": "pretrained=Qwen/Qwen3-8B",
      "model_num_parameters": 8190735360,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "9c925d64d72725edaf899c6cb9c377fd0709d9c5",
      "batch_size": "1",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "file_path": "Analogies\\Low\\Gemma-3-1b-it.json",
      "model": "hf",
      "model_args": "pretrained=google/gemma-3-1b-it",
      "model_num_parameters": 999885952,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "dcc83ea841ab6100d6b47a070329e1ba4cf78752",
      "batch_size": "1",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "google/mt5-large",
      "file_path": "Analogies\\Low\\Google-mt5-large.json",
      "model": "hf",
      "model_args": "pretrained=google/mt5-large,use_safetensors=True",
      "model_num_parameters": 1229581312,
      "model_dtype": "torch.float32",
      "model_revision": "main",
      "model_sha": "50b7223e98fcd124b0cabb1ec81bc6324c7df107",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "file_path": "Analogies\\Low\\Llama-3.1-8B-Instruct.json",
      "model": "hf",
      "model_args": "pretrained=meta-llama/Llama-3.1-8B-Instruct",
      "model_num_parameters": 8030261248,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "0e9e39f249a16976918f6564b8830bc894c89659",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "file_path": "Analogies\\Low\\Mistral-7B-Instruct-v0.3.json",
      "model": "hf",
      "model_args": "pretrained=mistralai/Mistral-7B-Instruct-v0.3",
      "model_num_parameters": 7248023552,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "e0bc86c23ce5aae1db576c8cca6f06f1f73af2db",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "file_path": "Analogies\\Low\\Qwen3-8B.json",
      "model": "hf",
      "model_args": "pretrained=Qwen/Qwen3-8B",
      "model_num_parameters": 8190735360,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "9c925d64d72725edaf899c6cb9c377fd0709d9c5",
      "batch_size": "1",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "file_path": "Analogies\\Medium\\Gemma-3-1b-it.json",
      "model": "hf",
      "model_args": "pretrained=google/gemma-3-1b-it",
      "model_num_parameters": 999885952,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "dcc83ea841ab6100d6b47a070329e1ba4cf78752",
      "batch_size": "1",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "google/mt5-large",
      "file_path": "Analogies\\Medium\\Google-mt5-large.json",
      "model": "hf",
      "model_args": "pretrained=google/mt5-large,use_safetensors=True",
      "model_num_parameters": 1229581312,
      "model_dtype": "torch.float32",
      "model_revision": "main",
      "model_sha": "50b7223e98fcd124b0cabb1ec81bc6324c7df107",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "file_path": "Analogies\\Medium\\Llama-3.1-8B-Instruct.json",
      "model": "hf",
      "model_args": "pretrained=meta-llama/Llama-3.1-8B-Instruct",
      "model_num_parameters": 8030261248,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "0e9e39f249a16976918f6564b8830bc894c89659",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "file_path": "Analogies\\Medium\\Mistral-7B-Instruct-v0.3.json",
      "model": "hf",
      "model_args": "pretrained=mistralai/Mistral-7B-Instruct-v0.3",
      "model_num_parameters": 7248023552,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "e0bc86c23ce5aae1db576c8cca6f06f1f73af2db",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "file_path": "Analogies\\Medium\\Qwen3-8B.json",
      "model": "hf",
      "model_args": "pretrained=Qwen/Qwen3-8B",
      "model_num_parameters": 8190735360,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "9c925d64d72725edaf899c6cb9c377fd0709d9c5",
      "batch_size": "1",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "file_path": "Analogies\\Mixed\\Gemma-3-1b-it.json",
      "model": "hf",
      "model_args": "pretrained=google/gemma-3-1b-it",
      "model_num_parameters": 999885952,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "dcc83ea841ab6100d6b47a070329e1ba4cf78752",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "google/mt5-large",
      "file_path": "Analogies\\Mixed\\Google-mt5-large.json",
      "model": "hf",
      "model_args": "pretrained=google/mt5-large,use_safetensors=True",
      "model_num_parameters": 1229581312,
      "model_dtype": "torch.float32",
      "model_revision": "main",
      "model_sha": "50b7223e98fcd124b0cabb1ec81bc6324c7df107",
      "batch_size": "4",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "file_path": "Analogies\\Mixed\\Llama-3.1-8B-Instruct.json",
      "model": "hf",
      "model_args": "pretrained=meta-llama/Llama-3.1-8B-Instruct",
      "model_num_parameters": 8030261248,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "0e9e39f249a16976918f6564b8830bc894c89659",
      "batch_size": "4",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "file_path": "Analogies\\Mixed\\Mistral-7B-Instruct-v0.3.json",
      "model": "hf",
      "model_args": "pretrained=mistralai/Mistral-7B-Instruct-v0.3",
      "model_num_parameters": 7248023552,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "e0bc86c23ce5aae1db576c8cca6f06f1f73af2db",
      "batch_size": "4",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "file_path": "Analogies\\Mixed\\Qwen3-8B.json",
      "model": "hf",
      "model_args": "pretrained=Qwen/Qwen3-8B",
      "model_num_parameters": 8190735360,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "9c925d64d72725edaf899c6cb9c377fd0709d9c5",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "file_path": "Analogies\\Monolingual_EN\\Gemma-3-1b-it.json",
      "model": "hf",
      "model_args": "pretrained=google/gemma-3-1b-it",
      "model_num_parameters": 999885952,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "dcc83ea841ab6100d6b47a070329e1ba4cf78752",
      "batch_size": "1",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "google/mt5-large",
      "file_path": "Analogies\\Monolingual_EN\\Google-mt5-large.json",
      "model": "hf",
      "model_args": "pretrained=google/mt5-large,use_safetensors=True",
      "model_num_parameters": 1229581312,
      "model_dtype": "torch.float32",
      "model_revision": "main",
      "model_sha": "50b7223e98fcd124b0cabb1ec81bc6324c7df107",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "file_path": "Analogies\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "model": "hf",
      "model_args": "pretrained=meta-llama/Llama-3.1-8B-Instruct",
      "model_num_parameters": 8030261248,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "0e9e39f249a16976918f6564b8830bc894c89659",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "file_path": "Analogies\\Monolingual_EN\\Mistral-7B-Instruct-v0.3.json",
      "model": "hf",
      "model_args": "pretrained=mistralai/Mistral-7B-Instruct-v0.3",
      "model_num_parameters": 7248023552,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "e0bc86c23ce5aae1db576c8cca6f06f1f73af2db",
      "batch_size": "2",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "file_path": "Analogies\\Monolingual_EN\\Qwen3-8B.json",
      "model": "hf",
      "model_args": "pretrained=Qwen/Qwen3-8B",
      "model_num_parameters": 8190735360,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "9c925d64d72725edaf899c6cb9c377fd0709d9c5",
      "batch_size": "1",
      "batch_sizes": [],
      "device": "cuda",
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    }
  ],
  "task_configs": [
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_high",
      "file_path": "Analogies\\High\\Gemma-3-1b-it.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_low",
      "file_path": "Analogies\\High\\Gemma-3-1b-it.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\High\\Gemma-3-1b-it.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\High\\Gemma-3-1b-it.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_high",
      "file_path": "Analogies\\High\\Google-mt5-large.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_low",
      "file_path": "Analogies\\High\\Google-mt5-large.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\High\\Google-mt5-large.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\High\\Google-mt5-large.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_high",
      "file_path": "Analogies\\High\\Llama-3.1-8B-Instruct.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_low",
      "file_path": "Analogies\\High\\Llama-3.1-8B-Instruct.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\High\\Llama-3.1-8B-Instruct.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\High\\Llama-3.1-8B-Instruct.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_high",
      "file_path": "Analogies\\High\\Mistral-7B-Instruct-v0.3.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_low",
      "file_path": "Analogies\\High\\Mistral-7B-Instruct-v0.3.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\High\\Mistral-7B-Instruct-v0.3.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\High\\Mistral-7B-Instruct-v0.3.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_high",
      "file_path": "Analogies\\High\\Mistral-7B-Instruct-v0.3.json",
      "task": "meronymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_high",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_low",
      "file_path": "Analogies\\High\\Mistral-7B-Instruct-v0.3.json",
      "task": "meronymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_low",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_medium",
      "file_path": "Analogies\\High\\Mistral-7B-Instruct-v0.3.json",
      "task": "meronymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_medium",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_mono",
      "file_path": "Analogies\\High\\Mistral-7B-Instruct-v0.3.json",
      "task": "meronymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_mono",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_high",
      "file_path": "Analogies\\High\\Qwen3-8B.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_low",
      "file_path": "Analogies\\High\\Qwen3-8B.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\High\\Qwen3-8B.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\High\\Qwen3-8B.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_high",
      "file_path": "Analogies\\Low\\Gemma-3-1b-it.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_low",
      "file_path": "Analogies\\Low\\Gemma-3-1b-it.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\Low\\Gemma-3-1b-it.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\Low\\Gemma-3-1b-it.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_high",
      "file_path": "Analogies\\Low\\Google-mt5-large.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_low",
      "file_path": "Analogies\\Low\\Google-mt5-large.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\Low\\Google-mt5-large.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\Low\\Google-mt5-large.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_high",
      "file_path": "Analogies\\Low\\Llama-3.1-8B-Instruct.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_low",
      "file_path": "Analogies\\Low\\Llama-3.1-8B-Instruct.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\Low\\Llama-3.1-8B-Instruct.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\Low\\Llama-3.1-8B-Instruct.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_high",
      "file_path": "Analogies\\Low\\Mistral-7B-Instruct-v0.3.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_low",
      "file_path": "Analogies\\Low\\Mistral-7B-Instruct-v0.3.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\Low\\Mistral-7B-Instruct-v0.3.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\Low\\Mistral-7B-Instruct-v0.3.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_high",
      "file_path": "Analogies\\Low\\Mistral-7B-Instruct-v0.3.json",
      "task": "meronymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_high",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_low",
      "file_path": "Analogies\\Low\\Mistral-7B-Instruct-v0.3.json",
      "task": "meronymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_low",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_medium",
      "file_path": "Analogies\\Low\\Mistral-7B-Instruct-v0.3.json",
      "task": "meronymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_medium",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_mono",
      "file_path": "Analogies\\Low\\Mistral-7B-Instruct-v0.3.json",
      "task": "meronymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_mono",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_high",
      "file_path": "Analogies\\Low\\Qwen3-8B.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_low",
      "file_path": "Analogies\\Low\\Qwen3-8B.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\Low\\Qwen3-8B.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\Low\\Qwen3-8B.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_high",
      "file_path": "Analogies\\Medium\\Gemma-3-1b-it.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_low",
      "file_path": "Analogies\\Medium\\Gemma-3-1b-it.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\Medium\\Gemma-3-1b-it.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\Medium\\Gemma-3-1b-it.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_high",
      "file_path": "Analogies\\Medium\\Google-mt5-large.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_low",
      "file_path": "Analogies\\Medium\\Google-mt5-large.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\Medium\\Google-mt5-large.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\Medium\\Google-mt5-large.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_high",
      "file_path": "Analogies\\Medium\\Llama-3.1-8B-Instruct.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_low",
      "file_path": "Analogies\\Medium\\Llama-3.1-8B-Instruct.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\Medium\\Llama-3.1-8B-Instruct.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\Medium\\Llama-3.1-8B-Instruct.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_high",
      "file_path": "Analogies\\Medium\\Mistral-7B-Instruct-v0.3.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_low",
      "file_path": "Analogies\\Medium\\Mistral-7B-Instruct-v0.3.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\Medium\\Mistral-7B-Instruct-v0.3.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\Medium\\Mistral-7B-Instruct-v0.3.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_high",
      "file_path": "Analogies\\Medium\\Mistral-7B-Instruct-v0.3.json",
      "task": "meronymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_high",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_low",
      "file_path": "Analogies\\Medium\\Mistral-7B-Instruct-v0.3.json",
      "task": "meronymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_low",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_medium",
      "file_path": "Analogies\\Medium\\Mistral-7B-Instruct-v0.3.json",
      "task": "meronymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_medium",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_mono",
      "file_path": "Analogies\\Medium\\Mistral-7B-Instruct-v0.3.json",
      "task": "meronymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_mono",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_high",
      "file_path": "Analogies\\Medium\\Qwen3-8B.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_low",
      "file_path": "Analogies\\Medium\\Qwen3-8B.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\Medium\\Qwen3-8B.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\Medium\\Qwen3-8B.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_all",
      "file_path": "Analogies\\Mixed\\Gemma-3-1b-it.json",
      "task": "analogies_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_all",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "hypernymy_all",
      "file_path": "Analogies\\Mixed\\Gemma-3-1b-it.json",
      "task": "hypernymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_all",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "meronymy_all",
      "file_path": "Analogies\\Mixed\\Gemma-3-1b-it.json",
      "task": "meronymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_all",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_all",
      "file_path": "Analogies\\Mixed\\Google-mt5-large.json",
      "task": "analogies_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_all",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "hypernymy_all",
      "file_path": "Analogies\\Mixed\\Google-mt5-large.json",
      "task": "hypernymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_all",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "meronymy_all",
      "file_path": "Analogies\\Mixed\\Google-mt5-large.json",
      "task": "meronymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_all",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_all",
      "file_path": "Analogies\\Mixed\\Llama-3.1-8B-Instruct.json",
      "task": "analogies_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_all",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "hypernymy_all",
      "file_path": "Analogies\\Mixed\\Llama-3.1-8B-Instruct.json",
      "task": "hypernymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_all",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "meronymy_all",
      "file_path": "Analogies\\Mixed\\Llama-3.1-8B-Instruct.json",
      "task": "meronymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_all",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_all",
      "file_path": "Analogies\\Mixed\\Mistral-7B-Instruct-v0.3.json",
      "task": "analogies_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_all",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "hypernymy_all",
      "file_path": "Analogies\\Mixed\\Mistral-7B-Instruct-v0.3.json",
      "task": "hypernymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_all",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_all",
      "file_path": "Analogies\\Mixed\\Mistral-7B-Instruct-v0.3.json",
      "task": "meronymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_all",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_all",
      "file_path": "Analogies\\Mixed\\Qwen3-8B.json",
      "task": "analogies_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_all",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "hypernymy_all",
      "file_path": "Analogies\\Mixed\\Qwen3-8B.json",
      "task": "hypernymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/hypernymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Hypernymy evaluation task with multilingual options",
        "alias": "hypernymy_all",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "meronymy_all",
      "file_path": "Analogies\\Mixed\\Qwen3-8B.json",
      "task": "meronymy_all",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_all.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_all",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_high",
      "file_path": "Analogies\\Monolingual_EN\\Gemma-3-1b-it.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_low",
      "file_path": "Analogies\\Monolingual_EN\\Gemma-3-1b-it.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\Monolingual_EN\\Gemma-3-1b-it.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/gemma-3-1b-it",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\Monolingual_EN\\Gemma-3-1b-it.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "google/gemma-3-1b-it"
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_high",
      "file_path": "Analogies\\Monolingual_EN\\Google-mt5-large.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_low",
      "file_path": "Analogies\\Monolingual_EN\\Google-mt5-large.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\Monolingual_EN\\Google-mt5-large.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "google/mt5-large",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\Monolingual_EN\\Google-mt5-large.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "google/mt5-large",
        "use_safetensors": true
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_high",
      "file_path": "Analogies\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_low",
      "file_path": "Analogies\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\Monolingual_EN\\Llama-3.1-8B-Instruct.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "meta-llama/Llama-3.1-8B-Instruct"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_high",
      "file_path": "Analogies\\Monolingual_EN\\Mistral-7B-Instruct-v0.3.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_low",
      "file_path": "Analogies\\Monolingual_EN\\Mistral-7B-Instruct-v0.3.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\Monolingual_EN\\Mistral-7B-Instruct-v0.3.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\Monolingual_EN\\Mistral-7B-Instruct-v0.3.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_high",
      "file_path": "Analogies\\Monolingual_EN\\Mistral-7B-Instruct-v0.3.json",
      "task": "meronymy_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_high",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_low",
      "file_path": "Analogies\\Monolingual_EN\\Mistral-7B-Instruct-v0.3.json",
      "task": "meronymy_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_low",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_medium",
      "file_path": "Analogies\\Monolingual_EN\\Mistral-7B-Instruct-v0.3.json",
      "task": "meronymy_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_medium",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "task_name": "meronymy_mono",
      "file_path": "Analogies\\Monolingual_EN\\Mistral-7B-Instruct-v0.3.json",
      "task": "meronymy_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/meronymy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Meronymy evaluation task with multilingual options",
        "alias": "meronymy_mono",
        "pretrained": "mistralai/Mistral-7B-Instruct-v0.3"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_high",
      "file_path": "Analogies\\Monolingual_EN\\Qwen3-8B.json",
      "task": "analogies_high",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_high.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_high",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_low",
      "file_path": "Analogies\\Monolingual_EN\\Qwen3-8B.json",
      "task": "analogies_low",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_low.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_low",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_medium",
      "file_path": "Analogies\\Monolingual_EN\\Qwen3-8B.json",
      "task": "analogies_medium",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_en_to_medium.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_medium",
        "pretrained": "Qwen/Qwen3-8B"
      }
    },
    {
      "model_name": "Qwen/Qwen3-8B",
      "task_name": "analogies_mono",
      "file_path": "Analogies\\Monolingual_EN\\Qwen3-8B.json",
      "task": "analogies_mono",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": "./lm_eval/tasks/NLP_JMU/semantic_analogy_questions_monolingual_en.json"
      },
      "test_split": "train",
      "doc_to_text": "{{prompt}}",
      "doc_to_target": "{{answer_index}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0,
        "description": "Analogies evaluation task with multilingual options",
        "alias": "analogies_mono",
        "pretrained": "Qwen/Qwen3-8B"
      }
    }
  ],
  "duplicates_found": []
}